{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa532a5e",
   "metadata": {},
   "source": [
    "### 3 problems we have\n",
    "1. We have 200 shuffle partitions but only few of them have data\n",
    "2. when there is a dominating key, and there is a partition skew\n",
    "3. I want to join orders with of distinct customers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a78b45d",
   "metadata": {},
   "source": [
    "### Solutiins to above 3 problems\n",
    "\n",
    "#AQE provides\n",
    "============\n",
    "1. dynamically coalesing the number of shuffle partitions\n",
    "2. dynamically handling partition skew\n",
    "3. dynamically switching join strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f5ce4d",
   "metadata": {},
   "source": [
    "### number of records:\n",
    "\n",
    "1. size of the data\n",
    "2. min and max of each column\n",
    "3. count of number of occurences of each key\n",
    "4. if data is reduced during the join it dynamically switch the join strategies like broadcast join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c13b5554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem no:1 We have 200 shuffle partitions but only few of them have data\n",
    "#solution: dynamically coalesing the number of shuffle partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f62fa231",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import getpass\n",
    "username = getpass.getuser()\n",
    "spark = SparkSession. \\\n",
    "builder. \\\n",
    "config('spark.ui.port', '0'). \\\n",
    "config(\"spark.sql.warehouse.dir\", f\"/user/itv015970/warehouse\"). \\\n",
    "enableHiveSupport(). \\\n",
    "master('yarn'). \\\n",
    "getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5e31c203",
   "metadata": {},
   "outputs": [],
   "source": [
    "order_schema = \"order_id long, order_date string, customer_id long, order_status string\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "de307afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_df = spark.read \\\n",
    ".format(\"csv\") \\\n",
    ".schema(order_schema) \\\n",
    ".load(\"/public/trendytech/orders/orders_1gb.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "319638ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_df.groupBy(\"order_status\").count().write.format(\"noop\").mode(\"overwrite\").save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "23df8a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check adaptive query is enabled or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "324fe539",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'false'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.conf.get(\"spark.sql.adaptive.enabled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3f58291e",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.adaptive.enabled\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "368ecdd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_df.groupBy(\"order_status\").count().write.format(\"noop\").mode(\"overwrite\").save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5787ac8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089a14d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebef9d70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fde891",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9962ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyspark 3",
   "language": "python",
   "name": "pyspark3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
