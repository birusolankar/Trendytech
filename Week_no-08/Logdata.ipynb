{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1128bfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import getpass\n",
    "username = getpass.getuser()\n",
    "spark = SparkSession. \\\n",
    "builder. \\\n",
    "config('spark.ui.port', '0'). \\\n",
    "config(\"spark.sql.warehouse.dir\", f\"/user/itv015970/warehouse\"). \\\n",
    "enableHiveSupport(). \\\n",
    "master('yarn'). \\\n",
    "getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c6590eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "logschema = \"loglevel string, logtime timestamp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4891f55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_df = spark.read \\\n",
    ".format(\"csv\") \\\n",
    ".schema(logschema) \\\n",
    ".load(\"/public/trendytech/datasets/logdata1m.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "80f0914d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+\n",
      "|loglevel|            logtime|\n",
      "+--------+-------------------+\n",
      "|    INFO|2015-08-08 20:49:22|\n",
      "|    WARN|2015-01-14 20:05:00|\n",
      "|    INFO|2017-06-14 00:08:35|\n",
      "|    INFO|2016-01-18 11:50:14|\n",
      "|   DEBUG|2017-07-01 12:55:02|\n",
      "+--------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "817b8bc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000000"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "175ee6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_df.createOrReplaceTempView(\"serverlogs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "18ccdde5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+\n",
      "|loglevel|            logtime|\n",
      "+--------+-------------------+\n",
      "|    INFO|2015-08-08 20:49:22|\n",
      "|    WARN|2015-01-14 20:05:00|\n",
      "|    INFO|2017-06-14 00:08:35|\n",
      "|    INFO|2016-01-18 11:50:14|\n",
      "|   DEBUG|2017-07-01 12:55:02|\n",
      "|    INFO|2014-02-26 12:34:21|\n",
      "|    INFO|2015-07-12 11:13:47|\n",
      "|    INFO|2017-04-15 01:20:18|\n",
      "|   DEBUG|2016-11-02 20:19:23|\n",
      "|    INFO|2012-08-20 10:09:44|\n",
      "|   DEBUG|2014-04-22 21:30:49|\n",
      "|    WARN|2013-12-06 17:54:15|\n",
      "|   DEBUG|2017-01-12 10:47:02|\n",
      "|   DEBUG|2016-06-25 11:06:42|\n",
      "|   ERROR|2015-06-28 19:25:05|\n",
      "|   DEBUG|2012-06-24 01:06:37|\n",
      "|    INFO|2014-12-09 09:53:54|\n",
      "|   DEBUG|2015-11-08 19:20:08|\n",
      "|    INFO|2017-07-21 18:34:18|\n",
      "|   DEBUG|2014-12-26 06:38:42|\n",
      "+--------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from serverlogs\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5e56b2a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+\n",
      "|loglevel|   month|\n",
      "+--------+--------+\n",
      "|    INFO|  August|\n",
      "|    WARN| January|\n",
      "|    INFO|    June|\n",
      "|    INFO| January|\n",
      "|   DEBUG|    July|\n",
      "|    INFO|February|\n",
      "|    INFO|    July|\n",
      "|    INFO|   April|\n",
      "|   DEBUG|November|\n",
      "|    INFO|  August|\n",
      "|   DEBUG|   April|\n",
      "|    WARN|December|\n",
      "|   DEBUG| January|\n",
      "|   DEBUG|    June|\n",
      "|   ERROR|    June|\n",
      "|   DEBUG|    June|\n",
      "|    INFO|December|\n",
      "|   DEBUG|November|\n",
      "|    INFO|    July|\n",
      "|   DEBUG|December|\n",
      "+--------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select loglevel, date_format(logtime, 'MMMM') as month from serverlogs\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0e65473b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+---------------+\n",
      "|loglevel|month|total_occurance|\n",
      "+--------+-----+---------------+\n",
      "|    WARN|  Apr|           8277|\n",
      "|   ERROR|  Apr|           4107|\n",
      "|   FATAL|  Apr|             83|\n",
      "|    INFO|  Apr|          29302|\n",
      "|   DEBUG|  Apr|          41869|\n",
      "|   ERROR|  Aug|           3987|\n",
      "|   DEBUG|  Aug|          42147|\n",
      "|    WARN|  Aug|           8381|\n",
      "|   FATAL|  Aug|             80|\n",
      "|    INFO|  Aug|          28993|\n",
      "|   DEBUG|  Dec|          41749|\n",
      "|    INFO|  Dec|          28874|\n",
      "|    WARN|  Dec|           8328|\n",
      "|   ERROR|  Dec|           4106|\n",
      "|   FATAL|  Dec|             94|\n",
      "|    INFO|  Feb|          28983|\n",
      "|   ERROR|  Feb|           4013|\n",
      "|    WARN|  Feb|           8266|\n",
      "|   DEBUG|  Feb|          41734|\n",
      "|   FATAL|  Feb|             72|\n",
      "+--------+-----+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select loglevel, date_format(logtime, 'MMM') as month, count(*) as total_occurance from serverlogs group by loglevel, month order by month\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5b272430",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = spark.sql(\"\"\"select loglevel, date_format(logtime, 'MMM') as month, int(date_format(logtime, 'M')) as month_num, count(*) as total_occurance \n",
    "from serverlogs \n",
    "group by loglevel, month, month_num\n",
    "order by month_num\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "49bdd728",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = result_df.drop(\"month_num\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a668da00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+---------------+\n",
      "|loglevel|month|total_occurance|\n",
      "+--------+-----+---------------+\n",
      "|   ERROR|  Jan|           4054|\n",
      "|   FATAL|  Jan|             94|\n",
      "|    WARN|  Jan|           8217|\n",
      "|    INFO|  Jan|          29119|\n",
      "|   DEBUG|  Jan|          41961|\n",
      "|    WARN|  Feb|           8266|\n",
      "|   DEBUG|  Feb|          41734|\n",
      "|   FATAL|  Feb|             72|\n",
      "|    INFO|  Feb|          28983|\n",
      "|   ERROR|  Feb|           4013|\n",
      "|   FATAL|  Mar|             70|\n",
      "|    INFO|  Mar|          29095|\n",
      "|   ERROR|  Mar|           4122|\n",
      "|   DEBUG|  Mar|          41652|\n",
      "|    WARN|  Mar|           8165|\n",
      "|   FATAL|  Apr|             83|\n",
      "|    INFO|  Apr|          29302|\n",
      "|   ERROR|  Apr|           4107|\n",
      "|   DEBUG|  Apr|          41869|\n",
      "|    WARN|  Apr|           8277|\n",
      "+--------+-----+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6bda7345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+\n",
      "|loglevel|   01|   02|   03|   04|   05|   06|   07|   08|   09|   10|   11|   12|\n",
      "+--------+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+\n",
      "|    INFO|29119|28983|29095|29302|28900|29143|29300|28993|29038|29018|23301|28874|\n",
      "|   ERROR| 4054| 4013| 4122| 4107| 4086| 4059| 3976| 3987| 4161| 4040| 3389| 4106|\n",
      "|    WARN| 8217| 8266| 8165| 8277| 8403| 8191| 8222| 8381| 8352| 8226| 6616| 8328|\n",
      "|   DEBUG|41961|41734|41652|41869|41785|41774|42085|42147|41433|41936|33366|41749|\n",
      "|   FATAL|   94|   72|   70|   83|   60|   78|   98|   80|   81|   92|16797|   94|\n",
      "+--------+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select loglevel, date_format(logtime, 'MM') as month from serverlogs\").groupBy('loglevel').pivot('month').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f8440a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+------+--------+--------+-------+-----+-----+-----+-----+--------+-------+---------+\n",
      "|loglevel|April|August|December|February|January| July| June|March|  May|November|October|September|\n",
      "+--------+-----+------+--------+--------+-------+-----+-----+-----+-----+--------+-------+---------+\n",
      "|    INFO|29302| 28993|   28874|   28983|  29119|29300|29143|29095|28900|   23301|  29018|    29038|\n",
      "|   ERROR| 4107|  3987|    4106|    4013|   4054| 3976| 4059| 4122| 4086|    3389|   4040|     4161|\n",
      "|    WARN| 8277|  8381|    8328|    8266|   8217| 8222| 8191| 8165| 8403|    6616|   8226|     8352|\n",
      "|   FATAL|   83|    80|      94|      72|     94|   98|   78|   70|   60|   16797|     92|       81|\n",
      "|   DEBUG|41869| 42147|   41749|   41734|  41961|42085|41774|41652|41785|   33366|  41936|    41433|\n",
      "+--------+-----+------+--------+--------+-------+-----+-----+-----+-----+--------+-------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select loglevel, date_format(logtime, 'MMMM') as month from serverlogs\").groupBy('loglevel').pivot('month').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b7437d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "month_list = ['January', 'Febraury', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "36317feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['January', 'Febraury', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']\n"
     ]
    }
   ],
   "source": [
    "print(month_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "11ecbef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+--------+-----+-----+-----+-----+-----+------+---------+-------+--------+--------+\n",
      "|loglevel|January|Febraury|March|April|  May| June| July|August|September|October|November|December|\n",
      "+--------+-------+--------+-----+-----+-----+-----+-----+------+---------+-------+--------+--------+\n",
      "|    INFO|  29119|    null|29095|29302|28900|29143|29300| 28993|    29038|  29018|   23301|   28874|\n",
      "|   ERROR|   4054|    null| 4122| 4107| 4086| 4059| 3976|  3987|     4161|   4040|    3389|    4106|\n",
      "|    WARN|   8217|    null| 8165| 8277| 8403| 8191| 8222|  8381|     8352|   8226|    6616|    8328|\n",
      "|   FATAL|     94|    null|   70|   83|   60|   78|   98|    80|       81|     92|   16797|      94|\n",
      "|   DEBUG|  41961|    null|41652|41869|41785|41774|42085| 42147|    41433|  41936|   33366|   41749|\n",
      "+--------+-------+--------+-----+-----+-----+-----+-----+------+---------+-------+--------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select loglevel, date_format(logtime, 'MMMM') as month from serverlogs\").groupBy('loglevel').pivot('month',month_list).count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31830fab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyspark 3",
   "language": "python",
   "name": "pyspark3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
